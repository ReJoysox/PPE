import streamlit as st
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="SafeGuard PRO", layout="centered")

st.markdown("""
    <style>
    .stApp { background-color: #0f172a; color: white; }
    .stMarkdown { text-align: center; }
    </style>
    """, unsafe_allow_html=True)

st.title("üõ°Ô∏è SafeGuard –ò–ò")
st.write("–°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ v5.0")

# 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –∏ –∫–µ—à–∏—Ä—É–µ–º
    model = YOLO('best.onnx', task='detect')
    return model

model = load_model()

# 3. –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
st.sidebar.header("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
conf_val = st.sidebar.slider("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", 0.1, 1.0, 0.5)
st.sidebar.write("---")
st.sidebar.info("–í —Ä–µ–∂–∏–º–µ '–ö–∞–º–µ—Ä–∞' —Å–Ω–∏–º–æ–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ. –≠—Ç–æ —Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–± –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤.")

# --- –§–£–ù–ö–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò ---
def process_result(img, model, conf):
    # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Ñ–æ—Ç–æ –≤ –º–∞—Å—Å–∏–≤
    img_rgb = np.array(img.convert("RGB"))
    img_cv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    
    # –ó–∞–ø—É—Å–∫ –ò–ò (imgsz=320 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
    results = model.predict(img, conf=conf, imgsz=320, verbose=False)
    boxes = results[0].boxes
    
    if len(boxes) == 0:
        return img_rgb, 0

    people = []
    protection_boxes = []

    # –†–∞–∑–±–∏—Ä–∞–µ–º –æ–±—ä–µ–∫—Ç—ã
    for box in boxes:
        cls_id = int(box.cls[0])
        label = model.names[cls_id].lower()
        coords = box.xyxy[0].tolist()
        
        if 'person' in label or 'human' in label:
            people.append(coords)
        else:
            protection_boxes.append(coords)
            # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É —Å–∞–º–æ–π –∑–∞—â–∏—Ç—ã
            cv2.rectangle(img_cv, (int(coords[0]), int(coords[1])), (int(coords[2]), int(coords[3])), (0, 255, 0), 3)
            cv2.putText(img_cv, label.upper(), (int(coords[0]), int(coords[1]-10)), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
    violations = 0
    for p in people:
        px1, py1, px2, py2 = p
        is_protected = False
        for prot in protection_boxes:
            rx1, ry1, rx2, ry2 = prot
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
            if not (rx2 < px1 or rx1 > px2 or ry2 < py1 or ry1 > py2):
                is_protected = True
                break
        
        if not is_protected:
            violations += 1
            # –†–∏—Å—É–µ–º –∫—Ä–∞—Å–Ω–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
            cv2.putText(img_cv, "NO PROTECTION", (int(px1), int(py1-15)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            cv2.rectangle(img_cv, (int(px1), int(py1)), (int(px2), int(py2)), (0, 0, 255), 2)
        else:
            # –ó–µ–ª–µ–Ω–∞—è —Ä–∞–º–∫–∞ –≤–æ–∫—Ä—É–≥ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
            cv2.rectangle(img_cv, (int(px1), int(py1)), (int(px2), int(py2)), (0, 255, 0), 1)

    return cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB), violations

# 4. –ò–ù–¢–ï–†–§–ï–ô–° –í–ö–õ–ê–î–û–ö
tab1, tab2 = st.tabs(["üì∑ –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∫–∞–º–µ—Ä—É", "üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª"])

with tab1:
    # –°–∞–º—ã–π —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± —Ä–∞–±–æ—Ç—ã —Å –∫–∞–º–µ—Ä–æ–π –≤ Streamlit
    cam_img = st.camera_input("–ù–∞–≤–µ–¥–∏—Ç–µ –∫–∞–º–µ—Ä—É –∏ —Å–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
    if cam_img:
        with st.spinner('–ù–µ–π—Ä–æ—Å–µ—Ç—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç...'):
            img_pil = Image.open(cam_img)
            res_img, count = process_result(img_pil, model, conf_val)
            st.image(res_img, use_column_width=True)
            if count > 0:
                st.error(f"‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–û –ù–ê–†–£–®–ï–ù–ò–ô: {count}")
            else:
                st.success("‚úÖ –í—Å–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –≤ —Å—Ä–µ–¥—Å—Ç–≤–∞—Ö –∑–∞—â–∏—Ç—ã")

with tab2:
    up_img = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ç–æ –∏–∑ –≥–∞–ª–µ—Ä–µ–∏", type=['jpg', 'png', 'jpeg'])
    if up_img:
        img_pil = Image.open(up_img)
        res_img, count = process_result(img_pil, model, conf_val)
        st.image(res_img, use_column_width=True)
        if count > 0:
            st.warning(f"–ù–∞–π–¥–µ–Ω–æ –Ω–∞—Ä—É—à–µ–Ω–∏–π: {count}")
