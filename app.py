import streamlit as st
from ultralytics import YOLO
import cv2
import numpy as np
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
import av

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="SafeGuard FAST", layout="centered")
st.title("üõ°Ô∏è SafeGuard –ò–ò: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LIVE")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    return YOLO('best.onnx', task='detect')

model = load_model()

# –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —á—É—Ç—å-—á—É—Ç—å –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
conf_val = 0.5

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê ---
def fast_logic(img, model):
    # imgsz=320 –¥–µ–ª–∞–µ—Ç —Ä–∞–±–æ—Ç—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –≤ 4 —Ä–∞–∑–∞ –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ 640
    results = model.predict(img, conf=conf_val, imgsz=320, verbose=False)
    boxes = results[0].boxes
    
    if len(boxes) == 0:
        return img

    people = []
    protection = []

    for box in boxes:
        c = box.xyxy[0].tolist()
        label = model.names[int(box.cls[0])].lower()
        if 'person' in label or 'human' in label:
            people.append(c)
        else:
            protection.append(c)
            # –†–∏—Å—É–µ–º —Ç–æ–Ω–∫–∏–µ —Ä–∞–º–∫–∏ (—Ç–æ–ª—Å—Ç—ã–µ –ª–∏–Ω–∏–∏ —Ç–æ—Ä–º–æ–∑—è—Ç –æ—Ç—Ä–∏—Å–æ–≤–∫—É)
            cv2.rectangle(img, (int(c[0]), int(c[1])), (int(c[2]), int(c[3])), (0, 255, 0), 2)

    for p in people:
        px1, py1, px2, py2 = p
        is_safe = any(not (r[2] < px1 or r[0] > px2 or r[3] < py1 or r[1] > py2) for r in protection)
        
        if is_safe:
            cv2.rectangle(img, (int(px1), int(py1)), (int(px2), int(py2)), (255, 255, 255), 1)
        else:
            cv2.putText(img, "ALERT", (int(px1), int(py1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            cv2.rectangle(img, (int(px1), int(py1)), (int(px2), int(py2)), (0, 0, 255), 1)
    
    return img

class VideoProcessor(VideoProcessorBase):
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        # –û–±—Ä–∞–±–æ—Ç–∫–∞
        processed = fast_logic(img, model)
        return av.VideoFrame.from_ndarray(processed, format="bgr24")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è WebRTC (–∏—Å–ø–æ–ª—å–∑—É–µ–º Google —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
RTC_CONFIG = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})

webrtc_streamer(
    key="fast-ppe",
    video_processor_factory=VideoProcessor,
    rtc_configuration=RTC_CONFIG,
    # –•–ê–ö ‚Ññ1: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã –¥–æ 320p
    media_stream_constraints={
        "video": {
            "width": {"ideal": 480},
            "height": {"ideal": 320},
            "frameRate": {"ideal": 15}
        },
        "audio": False,
    },
    async_processing=True, # –•–ê–ö ‚Ññ2: –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ
)

st.info("–î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ö–æ—Ä–æ—à–µ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ –∏ —Ñ–æ—Ä–º–∞—Ç ONNX.")
