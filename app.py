import streamlit as st
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="SafeGuard PRO", layout="centered")
st.title("üõ°Ô∏è SafeGuard –ò–ò")
st.write("–°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è —Å—Ä–µ–¥—Å—Ç–≤ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –∑–∞—â–∏—Ç—ã")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    try:
        model = YOLO('best.onnx', task='detect')
        return model
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ best.onnx: {e}")
        return None

model = load_model()

if model:
    # –°–∞–π–¥–±–∞—Ä —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    st.sidebar.write("### –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
    st.sidebar.write(list(model.names.values()))
    conf_val = st.sidebar.slider("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", 0.1, 1.0, 0.4)

    def process_frame(img):
        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB, –∑–∞—Ç–µ–º –≤ –º–∞—Å—Å–∏–≤ numpy, –∑–∞—Ç–µ–º –≤ BGR –¥–ª—è OpenCV
        img_rgb = np.array(img.convert("RGB"))
        img_cv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
        
        # 2. –ó–∞–ø—É—Å–∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        results = model.predict(img, conf=conf_val)
        boxes = results[0].boxes
        
        if len(boxes) == 0:
            return img_rgb

        # –°–ø–∏—Å–∫–∏ –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤
        people = []
        protection_boxes = []

        # 3. –°–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        for box in boxes:
            cls_id = int(box.cls[0])
            label = model.names[cls_id].lower()
            coords = box.xyxy[0].tolist() # [x1, y1, x2, y2]
            
            if 'person' in label or 'human' in label:
                people.append(coords)
            else:
                protection_boxes.append(coords)
                # –†–∏—Å—É–µ–º –∑–µ–ª–µ–Ω—É—é —Ä–∞–º–∫—É –¥–ª—è —Å–∞–º–æ–π –∑–∞—â–∏—Ç—ã (–∫–∞—Å–∫–∞/–∂–∏–ª–µ—Ç)
                cv2.rectangle(img_cv, (int(coords[0]), int(coords[1])), (int(coords[2]), int(coords[3])), (0, 255, 0), 3)
                cv2.putText(img_cv, label.upper(), (int(coords[0]), int(coords[1]-10)), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∑–∞—â–∏—Ç—ã
        for p in people:
            px1, py1, px2, py2 = p
            is_protected = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç—Å—è –ª–∏ –∫–∞–∫–∞—è-–ª–∏–±–æ –∑–∞—â–∏—Ç–∞ —Å —Ä–∞–º–∫–æ–π —ç—Ç–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
            for prot in protection_boxes:
                rx1, ry1, rx2, ry2 = prot
                # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
                if not (rx2 < px1 or rx1 > px2 or ry2 < py1 or ry1 > py2):
                    is_protected = True
                    break
            
            if is_protected:
                # –ß–µ–ª–æ–≤–µ–∫ –≤ –∑–∞—â–∏—Ç–µ ‚Äî —Ä–∏—Å—É–µ–º —Ç–æ–Ω–∫—É—é –±–µ–ª—É—é —Ä–∞–º–∫—É
                cv2.rectangle(img_cv, (int(px1), int(py1)), (int(px2), int(py2)), (255, 255, 255), 1)
            else:
                # –ß–µ–ª–æ–≤–µ–∫–∞ –ë–ï–ó –∑–∞—â–∏—Ç—ã ‚Äî –≤—ã–¥–µ–ª—è–µ–º –ö–†–ê–°–ù–´–ú
                # 1. –ù–∞–¥–ø–∏—Å—å –Ω–∞–¥ –≥–æ–ª–æ–≤–æ–π
                cv2.putText(img_cv, "NO PROTECTION", (int(px1), int(py1-15)), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                # 2. –†–∞–º–∫–∞ –≤–æ–∫—Ä—É–≥ –≥–æ–ª–æ–≤—ã
                head_h = int((py2 - py1) * 0.25)
                cv2.rectangle(img_cv, (int(px1), int(py1)), (int(px2), int(py1 + head_h)), (0, 0, 255), 3)
                # 3. –†–∞–º–∫–∞ –≤–æ–∫—Ä—É–≥ –≤—Å–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
                cv2.rectangle(img_cv, (int(px1), int(py1)), (int(px2), int(py2)), (0, 0, 255), 1)

        return cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)

    # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–∫–ª–∞–¥–æ–∫
    t1, t2 = st.tabs(["üé• –°–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ", "üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª"])

    with t1:
        cam_img = st.camera_input("–ù–∞–≤–µ–¥–∏—Ç–µ –∫–∞–º–µ—Ä—É")
        if cam_img:
            res = process_frame(Image.open(cam_img))
            st.image(res, width=500)

    with t2:
        up_img = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ç–æ", type=['jpg', 'png', 'jpeg'])
        if up_img:
            res = process_frame(Image.open(up_img))
            st.image(res, width=500)
else:
    st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ best.onnx")
