import streamlit as st
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
st.set_page_config(page_title="SafeGuard PRO", layout="centered")
st.title("üõ°Ô∏è SafeGuard –ò–ò")
st.write("–°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    return YOLO('best.onnx', task='detect')

model = load_model()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
conf_val = st.sidebar.slider("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ò–ò", 0.1, 1.0, 0.5)

def process_and_draw(img, model, conf):
    # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Ñ–æ—Ç–æ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV
    img_array = np.array(img)
    img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    h_img, w_img, _ = img_cv.shape

    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å
    results = model.predict(img, conf=conf)
    boxes = results[0].boxes

    # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
    people = []
    protection = []

    # –†–∞–∑–±–∏—Ä–∞–µ–º –æ–±—ä–µ–∫—Ç—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    for box in boxes:
        cls_id = int(box.cls[0])
        label = model.names[cls_id].lower()
        coords = box.xyxy[0].tolist() # [x1, y1, x2, y2]
        
        if label == 'person':
            people.append(coords)
        else:
            protection.append({'label': label, 'coords': coords})

    # –õ–æ–≥–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
    for p in people:
        px1, py1, px2, py2 = p
        has_protection = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞—â–∏—Ç–∞ –≤–Ω—É—Ç—Ä–∏ –∏–ª–∏ —Ä—è–¥–æ–º —Å —Ä–∞–º–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞
        for prot in protection:
            rx1, ry1, rx2, ry2 = prot['coords']
            # –ï—Å–ª–∏ —Ä–∞–º–∫–∞ –∑–∞—â–∏—Ç—ã –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç—Å—è —Å —Ä–∞–º–∫–æ–π —á–µ–ª–æ–≤–µ–∫–∞
            if not (rx2 < px1 or rx1 > px2 or ry2 < py1 or ry1 > py2):
                has_protection = True
                # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É –∑–∞—â–∏—Ç—ã (–∑–µ–ª–µ–Ω–∞—è)
                cv2.rectangle(img_cv, (int(rx1), int(ry1)), (int(rx2), int(ry2)), (0, 255, 0), 3)
                cv2.putText(img_cv, prot['label'].upper(), (int(rx1), int(ry1)-10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # –ï—Å–ª–∏ –∑–∞—â–∏—Ç—ã –Ω–µ—Ç ‚Äî —Ä–∏—Å—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –Ω–∞–¥ –≥–æ–ª–æ–≤–æ–π
        if not has_protection:
            # –í—ã—á–∏—Å–ª—è–µ–º –∑–æ–Ω—É –≥–æ–ª–æ–≤—ã (–≤–µ—Ä—Ö–Ω—è—è —á–∞—Å—Ç—å —Ä–∞–º–∫–∏ —á–µ–ª–æ–≤–µ–∫–∞)
            head_y = int(py1)
            cv2.rectangle(img_cv, (int(px1), head_y), (int(px2), int(py1 + (py2-py1)*0.2)), (0, 0, 255), 2)
            cv2.putText(img_cv, "!!! NO PROTECTION !!!", (int(px1), head_y - 15), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)
            # –†–∏—Å—É–µ–º –∫—Ä–∞—Å–Ω—É—é —Ä–∞–º–∫—É –≤–æ–∫—Ä—É–≥ —á–µ–ª–æ–≤–µ–∫–∞, —á—Ç–æ–±—ã –≤—ã–¥–µ–ª–∏—Ç—å –Ω–∞—Ä—É—à–∏—Ç–µ–ª—è
            cv2.rectangle(img_cv, (int(px1), int(py1)), (int(px2), int(py2)), (0, 0, 255), 1)

    return cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)

# –í–∫–ª–∞–¥–∫–∏
tab1, tab2 = st.tabs(["üì∑ –°–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ", "üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª"])

with tab1:
    img_file = st.camera_input("–ù–∞–≤–µ–¥–∏—Ç–µ –∫–∞–º–µ—Ä—É")
    if img_file is not None:
        img = Image.open(img_file)
        processed_img = process_and_draw(img, model, conf_val)
        st.image(processed_img, width=500)

with tab2:
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", type=['jpg', 'jpeg', 'png'])
    if uploaded_file is not None:
        img = Image.open(uploaded_file)
        processed_img = process_and_draw(img, model, conf_val)
        st.image(processed_img, width=500)
