import streamlit as st
from ultralytics import YOLO
import cv2
import numpy as np
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
import av

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="SafeGuard Mobile", layout="centered")
st.title("üõ°Ô∏è SafeGuard –ò–ò: Mobile LIVE")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    return YOLO('best.onnx', task='detect')

model = load_model()

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ---
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
# –í—ã–±–æ—Ä –∫–∞–º–µ—Ä—ã –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞
camera_option = st.sidebar.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–º–µ—Ä—É:",
    ("–§—Ä–æ–Ω—Ç–∞–ª—å–Ω–∞—è (Selfie)", "–û—Å–Ω–æ–≤–Ω–∞—è (Rear)"),
    index=0
)

# –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤—ã–±–æ—Ä –≤ –ø–æ–Ω—è—Ç–Ω—ã–π –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–∞ —Ñ–æ—Ä–º–∞—Ç
facing_mode = "user" if camera_option == "–§—Ä–æ–Ω—Ç–∞–ª—å–Ω–∞—è (Selfie)" else "environment"

conf_val = st.sidebar.slider("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", 0.1, 1.0, 0.5)

# --- –õ–û–ì–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò ---
def process_logic(img, model):
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è imgsz=320 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
    results = model.predict(img, conf=conf_val, imgsz=320, verbose=False)
    boxes = results[0].boxes
    
    if len(boxes) == 0:
        return img

    people = []
    protection = []

    for box in boxes:
        c = box.xyxy[0].tolist()
        label = model.names[int(box.cls[0])].lower()
        if 'person' in label or 'human' in label:
            people.append(c)
        else:
            protection.append(c)
            cv2.rectangle(img, (int(c[0]), int(c[1])), (int(c[2]), int(c[3])), (0, 255, 0), 2)

    for p in people:
        px1, py1, px2, py2 = p
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
        is_safe = any(not (r[2] < px1 or r[0] > px2 or r[3] < py1 or r[1] > py2) for r in protection)
        
        color = (0, 255, 0) if is_safe else (0, 0, 255)
        text = "SAFE" if is_safe else "NO PPE"
        
        cv2.rectangle(img, (int(px1), int(py1)), (int(px2), int(py2)), color, 1)
        cv2.putText(img, text, (int(px1), int(py1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    
    return img

class VideoProcessor(VideoProcessorBase):
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        processed = process_logic(img, model)
        return av.VideoFrame.from_ndarray(processed, format="bgr24")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è WebRTC
RTC_CONFIG = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})

# –ó–∞–ø—É—Å–∫ —Å—Ç—Ä–∏–º–µ—Ä–∞
ctx = webrtc_streamer(
    key="mobile-ppe",
    video_processor_factory=VideoProcessor,
    rtc_configuration=RTC_CONFIG,
    # –ü–ï–†–ï–î–ê–ï–ú –ü–ê–†–ê–ú–ï–¢–†–´ –ö–ê–ú–ï–†–´
    media_stream_constraints={
        "video": {
            "facingMode": facing_mode, # –í—ã–±–æ—Ä –∫–∞–º–µ—Ä—ã –∑–¥–µ—Å—å
            "width": {"ideal": 480},
            "height": {"ideal": 320},
            "frameRate": {"ideal": 15}
        },
        "audio": False,
    },
    async_processing=True,
)

if ctx.state.playing:
    st.success(f"–¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞: {camera_option}")
else:
    st.info("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–º–µ—Ä—É –≤ –±–æ–∫–æ–≤–æ–º –º–µ–Ω—é –∏ –Ω–∞–∂–º–∏—Ç–µ START")
